{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47cec46e-1196-4218-a1db-eb2fbe259691",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report, confusion_matrix\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b919d3e-af22-46c5-bc31-d606ee8e70c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DATA_PATH = \"./ecommerce_customer_data_custom_ratios.csv\"\n",
    "OUT_DIR = \"./mnt/data/models\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "# Standardize columns\n",
    "df.columns = [c.strip() for c in df.columns]\n",
    "\n",
    "# Basic cleaning choices (adjust to your data)\n",
    "if 'Returns' not in df.columns:\n",
    "    raise ValueError(\"Column 'Returns' not found.\")\n",
    "df['Returns'] = df['Returns'].fillna(0).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3cbf754-a4ca-4e5e-b5ef-17dbf311302b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final dataset shape: (250000, 7)\n",
      "Target distribution:\n",
      " Returns\n",
      "0    149231\n",
      "1    100769\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Drop personal id columns\n",
    "for c in ['Customer Name', 'Customer ID', 'CustomerID', 'Name']:\n",
    "    if c in df.columns:\n",
    "        df = df.drop(columns=[c])\n",
    "\n",
    "# Normalize age column\n",
    "if 'Customer Age' in df.columns and 'Age' in df.columns:\n",
    "    df['age'] = df['Customer Age'].fillna(df['Age'])\n",
    "    df = df.drop(columns=['Customer Age','Age'])\n",
    "elif 'Customer Age' in df.columns:\n",
    "    df = df.rename(columns={'Customer Age':'age'})\n",
    "elif 'Age' in df.columns:\n",
    "    df = df.rename(columns={'Age':'age'})\n",
    "\n",
    "# Coerce numeric columns\n",
    "for c in ['Product Price','Quantity','Total Purchase Amount','age']:\n",
    "    if c in df.columns:\n",
    "        df[c] = pd.to_numeric(df[c], errors='coerce')\n",
    "\n",
    "# Define features\n",
    "numeric_features = [c for c in ['Product Price','Quantity','Total Purchase Amount','age'] if c in df.columns]\n",
    "cat_features = [c for c in ['Product Category','Payment Method','Gender'] if c in df.columns]\n",
    "features = numeric_features + cat_features\n",
    "\n",
    "# Drop rows missing any of selected features or target\n",
    "df = df.dropna(subset=features + ['Returns'])\n",
    "X = df[features].copy()\n",
    "y = df['Returns'].astype(int).copy()\n",
    "\n",
    "print(\"Final dataset shape:\", X.shape)\n",
    "print(\"Target distribution:\\n\", y.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9be4826-dbbd-45ac-8d4b-195a2b2ffe36",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42, stratify=y)\n",
    "\n",
    "# Preprocessing\n",
    "numeric_transformer = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "# Use sparse=True to avoid dense matrix explosion\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(fill_value='missing', strategy='constant')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', numeric_transformer, numeric_features),\n",
    "    ('cat', categorical_transformer, cat_features)\n",
    "], sparse_threshold=0.0)  # keep sparse output where possible\n",
    "\n",
    "# Models: logistic + RF (RF with limited parallelism)\n",
    "models = {\n",
    "    'logreg': Pipeline([('pre', preprocessor),\n",
    "                       ('clf', LogisticRegression(class_weight='balanced', max_iter=1000, random_state=42))]),\n",
    "    'rf': Pipeline([('pre', preprocessor),\n",
    "                    ('clf', RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42, n_jobs=1))])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d4f33bbb-bd1b-4bd6-9563-665ccb1262c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training logreg ...\n",
      "logreg acc 0.5063 prec 0.40221848159178214 rec 0.46238960007938873 f1 0.43021028091314084 roc 0.4980139490288512\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.54      0.56     29846\n",
      "           1       0.40      0.46      0.43     20154\n",
      "\n",
      "    accuracy                           0.51     50000\n",
      "   macro avg       0.50      0.50      0.50     50000\n",
      "weighted avg       0.52      0.51      0.51     50000\n",
      "\n",
      "[[15996 13850]\n",
      " [10835  9319]]\n",
      "Training rf ...\n",
      "rf acc 0.54948 prec 0.4000842459983151 rec 0.23563560583506996 f1 0.2965900574569073 roc 0.4974151132041506\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.76      0.67     29846\n",
      "           1       0.40      0.24      0.30     20154\n",
      "\n",
      "    accuracy                           0.55     50000\n",
      "   macro avg       0.50      0.50      0.48     50000\n",
      "weighted avg       0.52      0.55      0.52     50000\n",
      "\n",
      "[[22725  7121]\n",
      " [15405  4749]]\n",
      "Best model: logreg metrics: {'acc': 0.5063, 'prec': 0.40221848159178214, 'rec': 0.46238960007938873, 'f1': 0.43021028091314084, 'roc': 0.4980139490288512, 'model': Pipeline(steps=[('pre',\n",
      "                 ColumnTransformer(sparse_threshold=0.0,\n",
      "                                   transformers=[('num',\n",
      "                                                  Pipeline(steps=[('imputer',\n",
      "                                                                   SimpleImputer(strategy='median')),\n",
      "                                                                  ('scaler',\n",
      "                                                                   StandardScaler())]),\n",
      "                                                  ['Product Price', 'Quantity',\n",
      "                                                   'Total Purchase Amount',\n",
      "                                                   'age']),\n",
      "                                                 ('cat',\n",
      "                                                  Pipeline(steps=[('imputer',\n",
      "                                                                   SimpleImputer(fill_value='missing',\n",
      "                                                                                 strategy='constant')),\n",
      "                                                                  ('onehot',\n",
      "                                                                   OneHotEncoder(handle_unknown='ignore'))]),\n",
      "                                                  ['Product Category',\n",
      "                                                   'Payment Method',\n",
      "                                                   'Gender'])])),\n",
      "                ('clf',\n",
      "                 LogisticRegression(class_weight='balanced', max_iter=1000,\n",
      "                                    random_state=42))])}\n",
      "Saved model to ./mnt/data/models\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "results = {}\n",
    "for name, pipe in models.items():\n",
    "    print(f\"Training {name} ...\")\n",
    "    pipe.fit(X_train, y_train)\n",
    "    y_pred = pipe.predict(X_test)\n",
    "    y_proba = pipe.predict_proba(X_test)[:,1] if hasattr(pipe.named_steps['clf'], 'predict_proba') else None\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_test, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "    roc = roc_auc_score(y_test, y_proba) if y_proba is not None else None\n",
    "    results[name] = {'acc':acc, 'prec':prec, 'rec':rec, 'f1':f1, 'roc':roc, 'model':pipe}\n",
    "    print(name, \"acc\", acc, \"prec\", prec, \"rec\", rec, \"f1\", f1, \"roc\", roc)\n",
    "    print(classification_report(y_test, y_pred, zero_division=0))\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Choose best by F1\n",
    "best_name = max(results.keys(), key=lambda k: results[k]['f1'])\n",
    "best_model = results[best_name]['model']\n",
    "print(\"Best model:\", best_name, \"metrics:\", results[best_name])\n",
    "\n",
    "# Save with compression to reduce memory footprint on disk\n",
    "joblib.dump(best_model, os.path.join(OUT_DIR, f\"{best_name}_model.joblib\"), compress=3)\n",
    "print(\"Saved model to\", OUT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0adb028-361c-4d23-9cb3-6325370cf62c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
